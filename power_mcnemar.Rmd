---
title: "power_mcnemar"
output:
  html_document: default
  pdf_document: default
---

# --- Settings ---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# --- Packages ---

```{r}

library(tidyverse)
library(MESS)

#library(PropCIs)
#library(gee)
#library(readxl)

```

# --- Analysis ---

# 1. explanation

The goal here will be to simulate the full space of possible outcomes in a mcenmar test.

Any mcnemar test is done on a 2x2 contingency table, like the one shown below

     -----------------
     |       |       |
     |   a   |   b   |
     |       |       |
     -----------------
     |       |       |
     |   c   |   d   |
     |       |       |
     -----------------

The cells -- a,b,c,d -- can be either thought of as counts or proportions. Most of the time, it is more intuitive for me to think in terms of proportions.

In the mcnemar test, often we have two measurements of a proportion and we care how that proportion changes from before to after. For example, in the study for which I am doing this power analysis, I am asking people "before", "Would you want to live forever?". And then after, I ask that same person "Would you want to live forever, if X?" (where X is some good thing, like "you maintained good physical and mental health"). So, we do the mcnemar's test because we want to see, how this new condition (maintaining good physical health) changes the proportion of people who say they want to live forever. So, for example, we might imagine the proportion who say they want to live forever "before"/at a baseline, to be something like 30% (data we've compiled from public opinion polling and our own surveys ranges from ~5% to ~30%). And we might imagine the proportion of people who say they want to live forever "after"/under the new condition (e.g. maintaining good physical health), to be higher--say 65%.

We can represent this as the row and column totals in the contingency table.

                   after
                   
               yes      no
                
            -----------------
            |       |       |
    b  yes  |   a   |   b   |  30% = (a+b)
    e       |       |       |
    f       -----------------
    o       |       |       |
    r  no   |   c   |   d   |  (100-30%)
    e       |       |       |
            -----------------
           
             65%   (100-65%)
          = (a+c)

But note, that if the same person is asked both questions, there are 4 total combinations of response options: (a) yes before & yes after, (c) no before & yes after, (d) no before & no after, (b) yes before & no after.

To keep a longer story short, figure out whether 30% before is different from 50% after, mcnemar's test compares just the proportions in cell's b and c -- i.e. the "discordant cells", where people flipped their responses (also sometimes referred to as p12 and p21, where the first number in subscript reference the row number and the second number in the subscript references the column number). So, the whole thing really depends on those people who flip their responses and how they do so relative to each other.

If there is no flipping at all, then the ncemar's test will be absolutely insignificant. Actually, it won't even yield a test statistic or p-value.

                   after
               yes      no
            
            -----------------
            |       |       |
    b  yes  |   30  |   0   |  30%
    e       |       |       |
    f       -----------------
    o       |       |       |
    r  no   |   0   |   70  |  70$
    e       |       |       |
            -----------------
               
               30%     70%
           
Here is that test for that.

```{r}
m1 <- matrix(c(30, 0, 0, 70), nrow = 2, byrow = TRUE)
m1
```
```{r}

mcnemar.test(m1)
```
Let's introduce just some trivial flipping (1 of before yes's flips and one of the 1 after no's flips). And as we see, no significant difference.

```{r}
m2 <- matrix(c(29, 1, 1, 69), nrow = 2, byrow = TRUE)
m2

```
```{r}
# note, row and column totals are still preserved
colSums(m2)
rowSums(m2)
```
```{r}
mcnemar.test(m2)
```

So, whether the intervention is significant and the "before" proportion is different from the "after" proportion really depends on the flipping in the discordant cells. And, here we are expected an increase in the "after" proportion relative to the "before". That is, we expect more people to say they want to live forever if we clarify that they get to do so in good health. The way for this to happen is for a bunch of people who answered "no" initially, to switch to "yes" afterwards, when the conditions are sweeter, but for none or not many people who answered "yes" before to switch to "no" afterwards (and after all, why would they? they said yes initially, and now things are only better).

So that might look something like this.

                   after
               yes      no
            
            -----------------
            |       |       |
    b  yes  |   30  |   0   |  30%
    e       | (30*1)| (30*0)|
    f       -----------------
    o       |       |       |
    r  no   |   35  |   35  |  70%
    e       |(70*.5)|(70*.5)|
            -----------------
               
               65%     35%
    

Here, we see that 100% of the initial yes's stuck with their yes (and 0% flipped to no). But 50% of the initial no's flipped to yes (and 50% stayed). This gives us 30% who initially said yes, and 65% who said yes afterwards, in the condition where they were explicitly told they would have good health. Is this significant?

Let's do mcenmar's test, to see if this difference is significant. It is. Indeed, very, very significant.

```{r}
m3 <- matrix(c(30, 0, 35, 35), nrow = 2, byrow = TRUE)
m3
```

```{r}
mcnemar.test(m3)
```

Okay, but before we collect data, we don't actually know what portion will flip in the discordant cells. Essentially, we don't have a sense of the size of our effect. But we can simulate various possibilities and then compute the power we would have under those possibilities. And then choose our sample size based on that knowledge.

In any power analysis, we always have these basic inputs and outputs:

- sample size
- power (1-false negative rate)
- effect size

With any 2 of the 3, we can figure out the third.

Here, the effect size is a function of the discordant cells:
- p12
- p21

Both G*power and the MESS packages have functions that can compute power for a mcnemar's test.

For the effect size portion of the calculation, G*Power asks for:

- the ratio of p12 to p21 (which they very confusingly call the "odds ratio" although it is not a true odds ratio)
- the proportion of the total responses that are in the discordant cells (i.e. p12 + p21)

Meanwhile, the MESS package power_mcnemar_test() ask's for:

- the ratio of p12 to p21 (which they call "psi")
- the proportion for the discordant cell, which has the lower proportion of responses

In either case, the effect size, is simply a function of:
- p12
- p21


Now, it's hard for me to directly think in terms of the portions (p12 and p21) of the discordant cells.
But it is easier for me to think about the proportion who say "yes" to the "before" question (i.e. the row percentage).
(Which also necessary gives the percentage "no" before. e.g. If I think 30% will say "yes" to the before question, I'm implying that 70% will say "no" to this question).
And then, I can think about the percentage of the beforehand "yeses" that I think will flip--which will give me p12 (i.e. if I think 30% will say "yes" beforehand, and that 95% will stick with yes, and thus 5% will flip, then I can compute that I think p12 will be 0.015, i.e. 30% * 5% = 1.5%).
Likewise, I can think about the percentage of the beforehand "no's" that will flip (which will give p21).

Let me provide a full example. Imagine, I think that beforehand the proportion saying yes will be 40%. And I think that that 90% of these will initial "yeses" will stick with that response afterwards too, and I think that 30% of the initial "no's" will flip, then I can compute that p12 = and p21 = . This is depicted below.

Just knowing this:

                   after
    
               yes      no
            
            -----------------
            |       |       |
    b  yes  |   ?   |   ?   |  40%
    e       | (?*.9)| (?*?) |
    f       -----------------
    o       |       |       |
    r  no   |    ?  |   ?   |  ?%
    e       | (?*?) | (?*.7)|
            -----------------
               
               ?%     ?%


Means we can fill in all this:


                   after
    
               yes      no
            
            -----------------
            |       |       |
    b  yes  |   36  |   4   |  40%
    e       |(40*.9)|(40*.1)|
    f       -----------------
    o       |       |       |
    r  no   |   18  |  42   |  60%
    e       |(60*.3)|(60*.7)|
            -----------------
               
               54%     46%


So let's say, this is indeed the situation we think we are in (40% yes beforehand, 90% of those yeses stay, 30% of the no's flip). How large of a sample would we need to collect to have 90% power. We can compute that with the function from the MESS package. According to the function, we would need just over 113 participants, to achieve this level of power. (If we use the same p12 and p21 values to do the same power analysis in G*power, we get n=114. Close enough.)


```{r}
# preset beliefs
yes_baseline <- 0.40
yes_stay <- 0.90
no_flip <- 0.30

# resultant discordant probs
p12 <- yes_baseline * (1-yes_stay)
p21 <- (1-yes_baseline) * no_flip

# power (accounting for this function's quirks)
MESS::power_mcnemar_test(power = 0.90,
                         psi = max(p12/p21, p21/p12), # needs to be above one, so always take higher ratio
                         paid = min(p12, p21), # always wants the smaller of the two
                         alternative = "two.sided")

```

Okay, but suppose we don't actually know exactly what the proportion "yes" beforehand is, and the portion of yes's and no's that we think will flip. Well, we can just loop through all the possibilities. There's only so many: proportion yes has to be some value from 0% to 100%, and same for the portion of yes's flipping and the proportion of no's flipping.

Since these inputs (portion yes to start, and portion of yes's flipping and portion of no's flipping) comprise the effect size here, we we can then either specify a power level and compute the sample size we would need to achieve that level of power, or specify a sample size and compute the level of power such a sample size would achieve.


# 2. Sample Size required for specific reasonable cases

In this section, I am going to do a more traditional power analysis. By just plugging in various plausible values for each of the inputs and examining how that effects the outcome power metrics of interest.

Okay, so to start, we will consider the range of possibilities for the proportion of people who will say yes.

From public polls, the range of values here is: 5% to 27%. And in our existing surveys, it was around 28% to 32%. Our survey has a sample size of 100, but the phrasing was closer to how the phrasing will be. The polls have larger samples (n=750 - n=3850), but the phrasing is farther off from what we wll probably go with. Nevertheless, I will consider this the range of plausible values to explore.

Next, I need to get a handle on the two remaining parameters that affect the effect size. The portion of yes's that flip. And the proportion of no's that flip. Now, all the scenarios improve on the state of living forever, from baseline. So, it really seem reasonable to expect not a single person to flip from "yes" before, to no afterward. On the other hand, we literally cannot compute power if the resultant p12 cell is zero. So for practical purposes it has to be at least some trivial value above zero. But making it some very very small trivial value will probably hugely inflate the effect sizes. So I will pick some small values that are not necessarily trivially small (e.g. 1%). For the portion of initial no's that flip, this is really where the uncertainty lies. So for this, I will just explore a range of values from basically no flipping, to a massive amount of flipping.

Finally, I have to decide whether I want to fix power level and explore needed sample size, or fix sample size and compute achieved power. I'd like to look at it both ways, but I will start by fixing power and exploring resultant sample sizes.

So, let me start off with just the most likely outcome I envision. This will be a situation with the following parameters:

- yes proportion before hand: 30%
- proportion of yes's the flip: 1%
- proportion of no's that flip: [5-50%]
- desired power: [90-99%]

Without using a loop, I compute the sample size needed for various values in this range of parameters.

```{r}
# preset values
yes_prop <- 0.30
yes_flip <- 0.01
no_flip <- 0.05
desired_power <- 0.90

# resultant discordant props
p12 <- yes_prop * yes_flip
p21 <- (1-yes_prop) * no_flip

# set mind and max
min_prop <- min(p12, p21)
max_prop <- max(p12, p21)

# print relevant effect size inputs
print(paste0("yes-before: ", round(100*yes_prop, 1), "%"))
print(paste0("yes-after: ", round(100*(yes_prop * (1-yes_flip) + (1-yes_prop) * no_flip), 1), "%"))
print(paste0("yes_flip: ", round(100*yes_flip, 1), "%"))
print(paste0("no_flip: ", round(100*no_flip, 1), "%"))
print(paste0("p_yes->no: ", round(100*p12, 1), "%"))
print(paste0("p_no->yes: ", round(100*p21, 1), "%"))

# compute needed sample size
MESS::power_mcnemar_test(power = desired_power,
                         psi = max_prop/min_prop,
                         paid = min_prop,
                         alternative = "two.sided")


```

```{r}
# preset values
yes_prop <- 0.30
yes_flip <- 0.01
no_flip <- 0.05
desired_power <- 0.95

# resultant discordant props
p12 <- yes_prop * yes_flip
p21 <- (1-yes_prop) * no_flip

# set mind and max
min_prop <- min(p12, p21)
max_prop <- max(p12, p21)

# print relevant effect size inputs
print(paste0("yes-before: ", round(100*yes_prop, 1), "%"))
print(paste0("yes-after: ", round(100*(yes_prop * (1-yes_flip) + (1-yes_prop) * no_flip), 1), "%"))
print(paste0("yes_flip: ", round(100*yes_flip, 1), "%"))
print(paste0("no_flip: ", round(100*no_flip, 1), "%"))
print(paste0("p_yes->no: ", round(100*p12, 1), "%"))
print(paste0("p_no->yes: ", round(100*p21, 1), "%"))

# compute needed sample size
MESS::power_mcnemar_test(power = desired_power,
                         psi = max_prop/min_prop,
                         paid = min_prop,
                         alternative = "two.sided")


```

```{r}
# preset values
yes_prop <- 0.30
yes_flip <- 0.01
no_flip <- 0.10
desired_power <- 0.95

# resultant discordant props
p12 <- yes_prop * yes_flip
p21 <- (1-yes_prop) * no_flip

# set mind and max
min_prop <- min(p12, p21)
max_prop <- max(p12, p21)

# print relevant effect size inputs
print(paste0("yes-before: ", round(100*yes_prop, 1), "%"))
print(paste0("yes-after: ", round(100*(yes_prop * (1-yes_flip) + (1-yes_prop) * no_flip), 1), "%"))
print(paste0("yes_flip: ", round(100*yes_flip, 1), "%"))
print(paste0("no_flip: ", round(100*no_flip, 1), "%"))
print(paste0("p_yes->no: ", round(100*p12, 1), "%"))
print(paste0("p_no->yes: ", round(100*p21, 1), "%"))

# compute needed sample size
MESS::power_mcnemar_test(power = desired_power,
                         psi = max_prop/min_prop,
                         paid = min_prop,
                         alternative = "two.sided")


```

Okay, I am starting to feel just plugging in all these possible values here. And would rather loop through all the possibilities and examine the results.

# 3. Power achieved in various plausible cases

Here, I will just explore the power that would be achieved for a range of, what I perceive to be plausible values for the parameters that affect power:

1. proportion saying yes before: as mentioned before, the polling and survey data we have has varied from 5% to 30% on this
2. the proportion of initial yes's that flip to no's: setting this low will increase power, by virtue of creating a large effect size (combined with even modestly larger proportion of initial no's switching to yes). but all of the scenario's make the conditions of immortality better. so, i don't want to bias myself in the "easy direction", but it's just really hard for me to imagine more than literally one or two people switching to no's. i honestly feel like what is reasonable is like 1-5% of yes's flipping. but i will explore up to 10% even 20% (even though that seems totally implausible to me)
3. the proportion of initial no's that flip to yes's: this is really the open question, and i feel like what will determine the size of the effect. so i want to explore a large range of possibilities, from unreasonably small (1%, 2%, 5%) to that large middle range of what seems possible (10% up to even 50%) and then maybe some very large change values (75%), although at that point, the effect would be so big and obvious as to obviously be very highly powered
4. sample size: here, i want to loop through the range of possible sample sizes that i could actually reasonably pay for (somewhere from 100 to 1000 total participants)


## 3.1. create dataframe

So, just preseting those values here, to loop through. And creating data frame to store desired outputs and inputs.

```{r, echo = FALSE, eval = TRUE}
# values to loop through
p_yes_before <- c(0.05, 0.10, 0.20, 0.30)
p_yes_flip <- c(0.01, 0.05, 0.10) 
p_no_flip <- c(0.01, 0.02, 0.05, 0.10, 0.20, 0.25, 0.30, 0.40, 0.50, 0.75)
n_val <- c(100, 200, 300, 500, 750, 1000) 

# initialize data frame
total_rows <- length(p_yes_before) * length(p_yes_flip) * length(p_no_flip) * length(n_val)
df_power <- data.frame(p_yes_before = double(total_rows),
                       p_yes_after = double(total_rows),
                       p_yes_flip = double(total_rows),
                       p_no_flip = double(total_rows),
                       p_yes2no = double(total_rows),
                       p_no2yes = double(total_rows),
                       n_val = double(total_rows),
                       power = double(total_rows),
                       psi = double(total_rows),
                       paid = double(total_rows))

# check
total_rows
df_power %>% 
   sample_n(10) # this is really just for knitting (so don't get crazy long output)

```

## 3.2. loop, compute, and save

Actually compute the achieved power, for the various reasonable input values.

```{r}

i <- 0
for(p_yes_before_i in p_yes_before){
  for(p_yes_flip_i in p_yes_flip){
    for(p_no_flip_i in p_no_flip){
      for(n_val_i in n_val){
        i <- i + 1
        
        # compute: props in discordant cells and yes's after
        p_yes2no <- p_yes_before_i * p_yes_flip_i
        p_no2yes <- (1 - p_yes_before_i) * p_no_flip_i
        p_yes_after <- p_yes_before_i*(1-p_yes2no) + p_no2yes
        
        # set min and max
        min_prop <- min(p_yes2no, p_no2yes)
        max_prop <- max(p_yes2no, p_no2yes)
        psi = max_prop / min_prop
        paid = min_prop
        
        # compute achieved power
        power_i <- MESS::power_mcnemar_test(n = n_val_i,
                                            psi = psi,
                                            paid = paid,
                                            alternative = "two.sided")$power

        # save
        df_power[i,]$p_yes_before <- p_yes_before_i
        df_power[i,]$p_yes_after <- p_yes_after
        df_power[i,]$p_yes_flip <- p_yes_flip_i
        df_power[i,]$p_no_flip <- p_no_flip_i
        df_power[i,]$p_yes2no <- p_yes2no
        df_power[i,]$p_no2yes <- p_no2yes
        df_power[i,]$n_val <- n_val_i
        df_power[i,]$power <- power_i
        df_power[i,]$psi <- psi
        df_power[i,]$paid <- paid
      
      }
    }
  }
}

```

## 3.3. view df

View the output we just computed.

```{r}
df_power %>% 
  sample_n(10) # this is really just for knitting (so don't get crazy long output)
```


## 3.4. graph & interpret results

From this chart, we can see that a sample size of 500, will give us 90% power of greater in any case where (1) the proportion of initial no's is 10% of greater, (2) the proportion of initial yes that flip is between 1% and 10%, (3) the initial proportion is anywhere from 5% to 30% (except in the one case, where the initial proportion is 30%, prop initial no's that flip is 10% and prop initial yes's that flip is also 10%, which has 80% power, and quickly bumps up to 90% if the proportion of initial no's that flip moves up even by a bit).

Given these results and reasonable budget constraints, I will collect a sample of 500 participants.

```{r, fig.width=12, fig.height=8}
plot_power <-
df_power %>% 
  ggplot(aes(x = n_val,
             y = power,
             color = as.factor(p_yes_before))) +
  geom_point() +
  geom_line() +
  facet_grid(p_yes_flip ~ p_no_flip) +
  scale_y_continuous(breaks = seq(0, 1, 0.1)) +
  geom_rect(ymax = 1.1, ymin = 0.9, xmin = 0, xmax = 1100, alpha = 0.025, fill = "blue", color = FALSE) +
  theme_bw() +
  labs(x = "Sample Size",
       y = "Power",
       color = "Initial Proportion Saying Yes",
       title = paste0("Power as Function Of:",
                      "\n (1) Sample Size (x-axis)",
                      " \n (2) Proportion of Initial No's That Flip (columns)",
                      "\n (3) Proportion of Initial Yes's That Flip (rows)",
                      "\n (4) Initial Proportion Saying Yes (colored lines)")) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "top",
        plot.title = element_text(hjust = 0.5),
        panel.grid.minor = element_blank())

plot_power

```

## 3.5. save graph

```{r}
if (FALSE){
ggsave(plot = plot_power,
       filename = "power_mcnemar_plot.pdf",
       width = 12,
       height = 8)
}
```


# 4. Before V. After Probs, as function of flipping

The main outcome of interest is the of course the difference in the portion of people saying yes they would want to live forever at baseline and the proportion who say yes in various scenarios. So, I want to see how that latter outcome (portion saying yes in a given scenario) is related to the proportion of initial yes's the flip and the proportion of initial no's the flip.

I already saved that outcome in the simulation in the previous section. So, I will just visualize those results now.

Anything to the left of the diagonal, means that the proportion of yes's increase from before to after. As we can see, in all the possibilities we simulated, that is the case. 

```{r, fig.width=13, fig.height=8}
df_power %>% 
  filter(n_val == 1000) %>%  # not dependent on sample size, so just pick one
  ggplot(aes(x = p_yes_before,
             y = p_yes_after)) +
  geom_point(size = 2, alpha = 0.75) +
  geom_line(size = 1.25, alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dotted") +
  facet_grid(p_yes_flip ~ p_no_flip) +
  scale_y_continuous(breaks = seq(0, 1, 0.1)) +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1)) +
  theme_bw() +
  labs(x = "Proportion Saying \"Yes\" Before",
       y = "Proportion Saying \"Yes\" After",
       title = paste0("Proportion Saying \"Yes\" After As A Function Of:",
                      "\n (1) Proportion Saying \"Yes\" Before (x-axis)",
                      " \n (2) Proportion of Initial No's That Flip (columns)",
                      "\n (3) Proportion of Initial Yes's That Flip (rows)")) +
  theme(axis.text.x = element_text(angle = 90,
                                   size = 6),
        plot.title = element_text(hjust = 0.5),
        panel.grid.minor = element_blank())

```



# --- END/MISC ---

# --- References ---

1. Intro to mcnemar's test
- An Introduction to Categorical Data Analysis. Alan Agresti. 3rd Edition. 2019. John Wiley & Sons, Inc.
--> see: Chapter 8 (Models for Matched Pairs), p. 228-229

- Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1). Danielle Navarro (bookdown translation: Emily Kothe). https://learningstatisticswithr.com/book/
--> see: Chapter 12 (Categorical Data Analysis), subsection 12.8 (The Mcnemar Test)

2. G-Power Manual (for explanation of mcnemar power calculations)
- https://www.gpower.hhu.de/fileadmin/redaktion/Fakultaeten/Mathematisch-Naturwissenschaftliche_Fakultaet/Psychologie/AAP/gpower/GPowerManual.pdf
--> see section 5, p. 14-15 for explanation of mcnemar power calculation

3. Papers on power calculations for mcnemar's test:
- Duffy, S. W. (1984). Asymptotic and exact power for the McNemar test and its analogue with R controls per case. Biometrics, 1005-1015.
--> link: https://www.jstor.org/stable/2531151
--> this is the paper the MESS package cites for it's mcnemar power calculation

- Connor, R. J. (1987). Sample size for testing differences in proportions for the paired-sample design. Biometrics, 207-211.
--> link: https://www.jstor.org/stable/2531961
--> this is the paper cited by the github package by greenwell that calculates power: https://gist.github.com/bgreenwell/a2ef7cb6d5f340b516a6ad0b4f26f447