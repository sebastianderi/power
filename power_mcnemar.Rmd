---
title: "power_mcnemar"
output: html_document
---

# --- Settings ---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# --- Packages ---

```{r}

library(tidyverse)
library(MESS)

#library(PropCIs)
#library(gee)
#library(readxl)

```

# --- Analysis ---

# 1. explanation

The goal here will be to simulate the full space of possible outcomes in a mcenmar test.

Any mcnemar test is done on a 2x2 contingency table, like the one shown below

-----------------
|       |       |
|   a   |   b   |
|       |       |
-----------------
|       |       |
|   c   |   d   |
|       |       |
-----------------

The cells -- a,b,c,d -- can be either thought of as counts or proportions. Most of the time, it is more intuitive for me to think in terms of proportions.

In the mcnemar test, often we have two measurements of a proportion and we care how that proportion changes from before to after. For example, in the study for which I am doing this power analysis, I am asking people "before", "Would you want to live forever?". And then after, I ask that same person "Would you want to live forever, if X?" (where X is some good thing, like "you maintained good physical and mental health"). So, we do the mcnemar's test because we want to see, how this new condition (maintaining good physical health) changes the proportion of people who say they want to live forever. So, for example, we might imagine the proportion who say they want to live forever "before"/at a baseline, to be something like 30% (data we've compiled from public opinion polling and our own surveys ranges from ~5% to ~30%). And we might imagine the proportion of people who say they want to live forever "after"/under the new condition (e.g. maintaining good physical health), to be higher--say 65%.

We can represent this as the row and column totals in the contingency table.


               after

           yes      no
        
        -----------------
        |       |       |
b  yes  |   a   |   b   |  30% = (a+b)
e       |       |       |
f       -----------------
o       |       |       |
r  no   |   c   |   d   |  (100-30%)
e       |       |       |
        -----------------
           
           65%   (100-65%)
        = (a+c)

But note, that if the same person is asked both questions, there are 4 total combinations of response options: (a) yes before & yes after, (c) no before & yes after, (d) no before & no after, (b) yes before & no after.

To keep a longer story short, figure out whether 30% before is different from 50% after, mcnemar's test compares just the proportions in cell's b and c -- i.e. the "discordant cells", where people flipped their responses (also sometimes referred to as p12 and p21, where the first number in subscript reference the row number and the second number in the subscript references the column number). So, the whole thing really depends on those people who flip their responses and how they do so relative to each other.

If there is no flipping at all, then the ncemar's test will be absolutely insignificant. Actually, it won't even yield a test statistic or p-value.

               after

           yes      no
        
        -----------------
        |       |       |
b  yes  |   30  |   0   |  30%
e       |       |       |
f       -----------------
o       |       |       |
r  no   |   0   |   70  |  70$
e       |       |       |
        -----------------
           
           30%     70%
           
Here is that test for that.

```{r}
m1 <- matrix(c(30, 0, 0, 70), nrow = 2, byrow = TRUE)
m1
```
```{r}

mcnemar.test(m1)
```
Let's introduce just some trivial flipping (1 of before yes's flips and one of the 1 after no's flips). And as we see, no significant difference.

```{r}
m2 <- matrix(c(29, 1, 1, 69), nrow = 2, byrow = TRUE)
m2

```
```{r}
# note, row and column totals are still preserved
colSums(m2)
rowSums(m2)
```
```{r}
mcnemar.test(m2)
```

So, whether the intervention is significant and the "before" proportion is different from the "after" proportion really depends on the flipping in the discordant cells. And, here we are expected an increase in the "after" proportion relative to the "before". That is, we expect more people to say they want to live forever if we clarify that they get to do so in good health. The way for this to happen is for a bunch of people who answered "no" initially, to switch to "yes" afterwards, when the conditions are sweeter, but for none or not many people who answered "yes" before to switch to "no" afterwards (and after all, why would they? they said yes initially, and now things are only better).

So that might look something like this.

               after

           yes      no
        
        -----------------
        |       |       |
b  yes  |   30  |   0   |  30%
e       | (30*1)| (30*0)|
f       -----------------
o       |       |       |
r  no   |   35  |   35  |  70%
e       |(70*.5)|(70*.5)|
        -----------------
           
           65%     35%


Here, we see that 100% of the initial yes's stuck with their yes (and 0% flipped to no). But 50% of the initial no's flipped to yes (and 50% stayed). This gives us 30% who initially said yes, and 65% who said yes afterwards, in the condition where they were explicitly told they would have good health. Is this significant?

Let's do mcenmar's test, to see if this difference is significant. It is. Indeed, very, very significant.

```{r}
m3 <- matrix(c(30, 0, 35, 35), nrow = 2, byrow = TRUE)
m3
```

```{r}
mcnemar.test(m3)
```

Okay, but before we collect data, we don't actually know what portion will flip in the discordant cells. Essentially, we don't have a sense of the size of our effect. But we can simulate various possibilities and then compute the power we would have under those possibilities. And then choose our sample size based on that knowledge.

In any power analysis, we always have these basic inputs and outputs:

- sample size
- power (1-false negative rate)
- effect size

With any 2 of the 3, we can figure out the third.

Here, the effect size is a function of the discordant cells:
- p12
- p21

Both G*power and the MESS packages have functions that can compute power for a mcnemar's test.

For the effect size portion of the calculation, G*Power asks for:

- the ratio of p12 to p21 (which they very confusingly call the "odds ratio" although it is not a true odds ratio)
- the proportion of the total responses that are in the discordant cells (i.e. p12 + p21)

Meanwhile, the MESS package power_mcnemar_test() ask's for:

- the ratio of p12 to p21 (which they call "psi")
- the proportion for the discordant cell, which has the lower proportion of responses

In either case, the effect size, is simply a function of:
- p12
- p21


Now, it's hard for me to directly think in terms of the portions (p12 and p21) of the discordant cells.
But it is easier for me to think about the proportion who say "yes" to the "before" question (i.e. the row percentage).
(Which also necessary gives the percentage "no" before. e.g. If I think 30% will say "yes" to the before question, I'm implying that 70% will say "no" to this question).
And then, I can think about the percentage of the beforehand "yeses" that I think will flip--which will give me p12 (i.e. if I think 30% will say "yes" beforehand, and that 95% will stick with yes, and thus 5% will flip, then I can compute that I think p12 will be 0.015, i.e. 30% * 5% = 1.5%).
Likewise, I can think about the percentage of the beforehand "no's" that will flip (which will give p21).

Let me provide a full example. Imagine, I think that beforehand the proportion saying yes will be 40%. And I think that that 90% of these will initial "yeses" will stick with that response afterwards too, and I think that 30% of the initial "no's" will flip, then I can compute that p12 = and p21 = . This is depicted below.

Just knowing this:

               after

           yes      no
        
        -----------------
        |       |       |
b  yes  |   ?   |   ?   |  40%
e       | (?*.9)| (?*?) |
f       -----------------
o       |       |       |
r  no   |    ?  |   ?   |  ?%
e       | (?*?) | (?*.7)|
        -----------------
           
           ?%     ?%


Means we can fill in all this:


               after

           yes      no
        
        -----------------
        |       |       |
b  yes  |   36  |   4   |  40%
e       |(40*.9)|(40*.1)|
f       -----------------
o       |       |       |
r  no   |   18  |  42   |  60%
e       |(60*.3)|(60*.7)|
        -----------------
           
           54%     46%


So let's say, this is indeed the situation we think we are in (40% yes beforehand, 90% of those yeses stay, 30% of the no's flip). How large of a sample would we need to collect to have 90% power. We can compute that with the function from the MESS package. According to the function, we would need just over 113 participants, to achieve this level of power. (If we use the same p12 and p21 values to do the same power analysis in G*power, we get n=114. Close enough.)


```{r}
# preset beliefs
yes_baseline <- 0.40
yes_stay <- 0.90
no_flip <- 0.30

# resultant discordant probs
p12 <- yes_baseline * (1-yes_stay)
p21 <- (1-yes_baseline) * no_flip

# power (accounting for this function's quirks)
MESS::power_mcnemar_test(power = 0.90,
                         psi = max(p12/p21, p21/p12), # needs to be above one, so always take higher ratio
                         paid = min(p12, p21), # always wants the smaller of the two
                         alternative = "two.sided")

```

Okay, but suppose we don't actually know exactly what the proportion "yes" beforehand is, and the portion of yes's and no's that we think will flip. Well, we can just loop through all the possibilities. There's only so many: proportion yes has to be some value from 0% to 100%, and same for the portion of yes's flipping and the proportion of no's flipping.

Since these inputs (portion yes to start, and portion of yes's flipping and portion of no's flipping) comprise the effect size here, we we can then either specify a power level and compute the sample size we would need to achieve that level of power, or specify a sample size and compute the level of power such a sample size would achieve.


# 2. setup (effect size + power --> n)

To start, I will loop through all the possible effect sizes, and power levels (since all of these values are bounded between 0 and 1). And compute the sample size I would need for that given level of power and effect size.

# 3. create dataframe

```{r}
# values to loop through
p_baseline <- seq(0, 1, 0.1)
p_yes_stay <- seq(0, 1, 0.1)
p_no_flip <- seq(0, 1, 0.1)
power_val <- seq(0, 1, 0.1)

# initialize data frame
total_rows <- length(p_baseline) * length(p_yes_stay) * length(p_no_flip) * length(power_val)
df_power <- data.frame(p_baseline = double(total_rows),
                       p_yes_stay = double(total_rows),
                       p_no_flip = double(total_rows),
                       power_val = double(total_rows),
                       p12 = double(total_rows),
                       p21 = double(total_rows),
                       psi = double(total_rows),
                       paid = double(total_rows),
                       n = double(total_rows))

# check
total_rows
df_power

```
# 4. compute and save

```{r}
p_baseline <- seq(0, 1, 0.1)
p_yes_stay <- seq(0, 1, 0.1)
p_no_flip <- seq(0, 1, 0.1)
power_val <- seq(0, 1, 0.1)

i <- 0
for(p_baseline_i in p_baseline){
  for(p_yes_stay_i in p_yes_stay){
    for(p_no_flip_i in p_no_flip){
      for(power_val_i in power_val){
        i <- i + 1
        
        # resultant discordant probs
        p12 <- p_baseline_i * (1 - p_yes_stay_i)
        p21 <- (1 - p_baseline_i) * p_no_flip_i
        
        # compute power and save
        df_power[i,]$p_baseline <- p_baseline_i
        df_power[i,]$p_yes_stay <- p_yes_stay_i
        df_power[i,]$p_no_flip <- p_no_flip_i
        df_power[i,]$power_val <- power_val_i
        df_power[i,]$p12 <- p12
        df_power[i,]$p21 <- p21
        df_power[i,]$psi <- max(p12/p21, p21/p12)
        df_power[i,]$paid <- min(p12, p21)
        #df_power[i,]$n <- MESS::power_mcnemar_test(power = power_val_i,
        #                                           psi = max(p12/p21, p21/p12), # needs to be above one, so always take higher ratio
        #                                           paid = min(p12, p21), # always wants the smaller of the two
        #                                           alternative = "two.sided")
      
      }
    }
  }
}

```

```{r}
df_power
```


# 5. just some reasonable possibilities

In this section, I am going to do a more traditional power analysis. By just plugging in various plausible values for each of the inputs and examining how that effects the outcome power metrix of interest.

Okay, so to start, we will consider the range of possibilities for the proportion of people who will say yes.

From public polls, the range of values here is: 5% to 27%. And in our existing surveys, it was around 28% to 32%. Our survey has a sample size of 100, but the phrasing was closer to how the phrasing will be. The polls have larger samples (n=750 - n=3850), but the phrasing is farther off from what we wll probably go with. Nevertheless, I wil consider this the range of plausible values to explore.



# --- END/MISC ---

# --- References ---

1. Intro to mcnemar's test
- An Introduction to Categorical Data Analysis. Alan Agresti. 3rd Edition. 2019. John Wiley & Sons, Inc.
--> see: Chapter 8 (Models for Matched Pairs), p. 228-229

- Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1). Danielle Navarro (bookdown translation: Emily Kothe). https://learningstatisticswithr.com/book/
--> see: Chapter 12 (Categorical Data Analysis), subsection 12.8 (The Mcnemar Test)

2. G-Power Manual (for explanation of mcnemar power calculations)
- https://www.gpower.hhu.de/fileadmin/redaktion/Fakultaeten/Mathematisch-Naturwissenschaftliche_Fakultaet/Psychologie/AAP/gpower/GPowerManual.pdf
--> see section 5, p. 14-15 for explanation of mcnemar power calculation

3. Papers on power calculations for mcnemar's test:
- Duffy, S. W. (1984). Asymptotic and exact power for the McNemar test and its analogue with R controls per case. Biometrics, 1005-1015.
--> link: https://www.jstor.org/stable/2531151
--> this is the paper the MESS package cites for it's mcnemar power calculation

- Connor, R. J. (1987). Sample size for testing differences in proportions for the paired-sample design. Biometrics, 207-211.
--> link: https://www.jstor.org/stable/2531961
--> this is the paper cited by the github package by greenwell that calculates power: https://gist.github.com/bgreenwell/a2ef7cb6d5f340b516a6ad0b4f26f447